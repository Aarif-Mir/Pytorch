{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aarif-Mir/Pytorch/blob/main/14_pytorch_rnn_based_qa_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "92JvvYftu_-c",
        "outputId": "8a10fade-1bfa-4012-a16e-5062474989e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c359b7be-cc86-468c-b132-6bdf2964fb0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c359b7be-cc86-468c-b132-6bdf2964fb0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c359b7be-cc86-468c-b132-6bdf2964fb0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c359b7be-cc86-468c-b132-6bdf2964fb0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4b897f9d-2638-4d3d-8448-a18871fd9cd9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b897f9d-2638-4d3d-8448-a18871fd9cd9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4b897f9d-2638-4d3d-8448-a18871fd9cd9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/100_Unique_QA_Dataset.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfV7_SMHerpm",
        "outputId": "c136c943-2e93-4ca2-d36c-94a52471d2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "NWdOVkZ1viJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('What is the capital of France?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnGY1SR0v78p",
        "outputId": "8db71d15-a3fe-4e95-df31-da690af6eec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab\n",
        "vocab = {'<UNK>':0}"
      ],
      "metadata": {
        "id": "tld5UfhqvrRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  for token in merged_tokens:\n",
        "\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)\n"
      ],
      "metadata": {
        "id": "XxpiMiXtw4oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "9LSxaRRuxHlv",
        "outputId": "b0b28215-df13-4f19-fc21-1def89ab9fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDWgT_OoyGJM",
        "outputId": "283080f2-07c7-4607-f6cb-7e010aee35ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiFFMACho2D-",
        "outputId": "dfb12414-66e0-4244-90e4-381c3472df16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words to numerical indices\n",
        "def text_to_indices(text, vocab):\n",
        "\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text"
      ],
      "metadata": {
        "id": "BUBXvBNovvQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices(\"what is transfer-learning \", vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phdJw6IQzax2",
        "outputId": "5318dece-f807-48df-9173-2477bbe67c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "k-haYG7WzjHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTl50mTnp4fd",
        "outputId": "afeff677-e210-4830-b765-b9be3ecacfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "    # print(numerical_question)   # not a tensor\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ],
      "metadata": {
        "id": "PElUlPYT0gqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, vocab)"
      ],
      "metadata": {
        "id": "InSZ-ZIm1Y1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7OTRaUNqdcP",
        "outputId": "8d4734a1-a5f2-42bc-b065-6549f5fbf9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)    # padding required if batch_size > 1"
      ],
      "metadata": {
        "id": "BMVDt3h-1gMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question, answer in dataloader:\n",
        "#   print(question, answer)\n",
        "  print(question, answer[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40MDNe0v1iMN",
        "outputId": "0c964e6f-01f7-4ad2-c39a-4c72bc2ed59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 10,  75, 208]]) tensor([209])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([121])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([16])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([102])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([260])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([273])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([72])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([160])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([254])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([268])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([311])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([238])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([65])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([41])\n",
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([149])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([36])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([244])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([156])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([207])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([110])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([100])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([321])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([249])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([317])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([121])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([185])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([170])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([225])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([49])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([36])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([23])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([136])\n",
            "tensor([[ 10,  75, 111]]) tensor([112])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([259])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([9])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([134])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([58])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([162])\n",
            "tensor([[10, 75, 76]]) tensor([77])\n",
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([287])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([155])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([154])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([6])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([85])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([28])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([53])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([61])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([7])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([145])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([95])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([184])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([191])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([124])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([106])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([316])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([166])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([132])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([280])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([298])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([295])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([246])\n",
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([220])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([74])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([68])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([205])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([205])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([36])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([179])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([215])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([131])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([54])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([173])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([307])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([285])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([188])\n",
            "tensor([[10, 96,  3, 97]]) tensor([98])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([128])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([276])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([116])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([85])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([194])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([91])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([32])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([114])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([99])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([52])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([233])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([113])\n",
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([199])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "SrJNCywq14Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)   # we will not use the sequential container in it as the rnn will produce a tuple having 2 items and the sequential container expects only one , rnn result:  --> all outputs--> (O1-0i) and Oi(final one)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded_question = self.embedding(question)\n",
        "    hidden, final = self.rnn(embedded_question)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "y2XLQyi6GN61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ðŸ“Œ Important Points about `batch_first=True` and Batch Size\n",
        "\n",
        "* We **never specify batch size inside the model**; it comes automatically from the input tensor during training.\n",
        "* `batch_first=True` only tells PyTorch that the input shape should be **(batch_size, sequence_length, features)**.\n",
        "* The input we pass to the model must already have a batch dimension.\n",
        "  Example: shape `(1, 6)` for batch of 1, or `(32, 6)` for batch of 32.\n",
        "* Layers like `Embedding`, `RNN`, and `Linear` automatically adapt to the batch size given in the forward pass.\n",
        "* The RNN outputs two results:\n",
        "\n",
        "  * `hidden` â†’ outputs for **all time steps**\n",
        "  * `final` â†’ final hidden state used for prediction\n",
        "* `final.squeeze(0)` removes an unnecessary extra dimension before passing it to `Linear`.\n"
      ],
      "metadata": {
        "id": "n2b4U-Vu1L9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ðŸ“Œ Notes: RNN Input Shapes (Batch, Sequence, Input Size)\n",
        "\n",
        "#### ðŸ”· Key Points\n",
        "\n",
        "* In an RNN, the expected input shape is:\n",
        "\n",
        "  ```\n",
        "  [batch_size, sequence_length, input_size]\n",
        "  ```\n",
        "* We **do not specify** `batch_size` or `sequence_length` in the RNN constructor.\n",
        "\n",
        "  * These values come **automatically from the input data** during the forward pass.\n",
        "* We only specify:\n",
        "\n",
        "  * `input_size` â†’ dimensionality of the feature vector at each time step\n",
        "  * `hidden_size` â†’ number of units in the RNNâ€™s hidden state\n",
        "\n",
        "---\n",
        "\n",
        "#### ðŸ”· Relation with Embedding Layer\n",
        "\n",
        "```python\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "rnn = nn.RNN(input_size=50, hidden_size=64, batch_first=True)\n",
        "```\n",
        "\n",
        "* The embedding converts each token (word index) into a 50-dimensional vector.\n",
        "* Therefore:\n",
        "\n",
        "  ```\n",
        "  input_size = embedding_dim = 50\n",
        "  ```\n",
        "* `sequence_length` = number of tokens in each sentence (comes from data)\n",
        "* `batch_size` = number of sentences processed together (comes from DataLoader)\n",
        "\n",
        "---\n",
        "\n",
        "#### ðŸ”· Visual Shape Flow\n",
        "\n",
        "| Stage                       | Shape                                        |\n",
        "| --------------------------- | -------------------------------------------- |\n",
        "| Raw tokens from dataset     | `(batch_size, sequence_length)`              |\n",
        "| After Embedding             | `(batch_size, sequence_length, 50)`          |\n",
        "| RNN Output (all time steps) | `(batch_size, sequence_length, hidden_size)` |\n",
        "| Final hidden state          | `(num_layers, batch_size, hidden_size)`      |\n",
        "\n",
        "---\n",
        "\n",
        "#### ðŸŽ¯ Final Summary\n",
        "\n",
        "> We only define `input_size` and `hidden_size` in an RNN.\n",
        "> `input_size` equals the embedding dimension.\n",
        "> `batch_size` and `sequence_length` are **not fixed values**, so they are **NOT passed manually** â€” they are determined automatically from the input tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "_YJoR1Xa5M8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)\n",
        "y = nn.RNN(50, 64, batch_first=True)   # shape of d: torch.Size([1, 1, 64])\n",
        "# y = nn.RNN(50, 64)       #shape of d: torch.Size([1, 6, 64])\n",
        "z = nn.Linear(64, 324)\n",
        "\n",
        "a = dataset[0][0].reshape(1,6)\n",
        "print(\"shape of a:\", a.shape)\n",
        "b = x(a)\n",
        "print(\"shape of b:\", b.shape)\n",
        "c, d = y(b)                                # c = output for each time step â†’ (batch, sequence, hidden) and d = last hidden state â†’ (layers, batch, hidden)\n",
        "print(\"shape of c:\", c.shape)\n",
        "print(\"shape of d:\", d.shape)\n",
        "\n",
        "e = z(d.squeeze(0))\n",
        "\n",
        "print(\"shape of e:\", e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al9891aUW0e_",
        "outputId": "d2074ffe-927e-4bee-e7ab-2530ae4a20b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a: torch.Size([1, 6])\n",
            "shape of b: torch.Size([1, 6, 50])\n",
            "shape of c: torch.Size([1, 6, 64])\n",
            "shape of d: torch.Size([1, 1, 64])\n",
            "shape of e: torch.Size([1, 324])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happens if you donâ€™t add the batch dim (i.e., skip reshape)?**\n",
        "\n",
        "- If a.shape == [6]\n",
        "- then after b = x(a),\n",
        "- b.shape == [6, 50].\n",
        "\n",
        "**RNN expects 3-D input. PyTorchâ€™s RNN can accept either:**\n",
        "\n",
        "- (seq_len, batch, input_size) when batch_first=False (default), or\n",
        "\n",
        "- (batch, seq_len, input_size) when batch_first=True.\n",
        "\n",
        "If batch_first=True and you pass [6, 50], PyTorch will error because it expects 3 dims.\n",
        "\n",
        "If batch_first=False and you pass [6, 50], PyTorch will interpret that as [seq_len, input_size] â€” but it still expects [seq_len, batch, input_size], so again itâ€™s missing the batch dimension and youâ€™ll likely get an error. In short: RNN requires 3D input.\n",
        "\n",
        "So embedding alone can work with [6], but RNN will not, unless you reshape/unsqueeze to provide the missing dimension."
      ],
      "metadata": {
        "id": "gCVBd-V4yolj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Lquae9tm0Y",
        "outputId": "d4d5daa8-72f5-4ad4-ef5e-603eb74d0269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x(\"Who painted the Mona Lisa?\")   # embedding(): argument 'indices' (position 2) must be Tensor, not str\n",
        "x(dataset[0][0].reshape(1,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhIfES5Vs8Y_",
        "outputId": "fc9bcee0-3a3a-4074-8295-20005a96b9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-8.2547e-01, -1.6614e+00, -4.5921e-01,  1.7657e+00,  1.1599e+00,\n",
              "           1.2349e+00, -8.7584e-02,  9.7212e-01,  2.6486e+00, -6.6074e-01,\n",
              "          -1.1435e+00, -7.8254e-01,  2.8225e+00,  1.3831e+00,  9.3745e-01,\n",
              "           9.8360e-02,  4.9870e-01,  8.9597e-01, -2.2822e+00,  1.9356e-01,\n",
              "           4.8137e-01,  1.1546e+00,  6.8411e-01,  1.3812e+00,  3.1939e-01,\n",
              "          -9.2934e-01, -5.8292e-01,  2.8390e-01, -2.1280e+00,  4.2512e-01,\n",
              "           1.4613e+00,  1.0415e+00, -6.2212e-01,  8.8052e-01, -1.0555e+00,\n",
              "          -5.1885e-01, -2.9878e-01, -3.9683e-01, -1.7984e+00,  6.8381e-01,\n",
              "          -3.3902e-02,  2.9413e+00,  1.3617e+00, -5.9850e-01, -1.6009e+00,\n",
              "           1.2908e+00, -3.5289e-01,  3.5460e-01, -9.1069e-01,  2.0511e-01],\n",
              "         [ 2.4143e-01, -1.6102e+00, -7.7504e-01,  1.2313e-01,  2.8644e-01,\n",
              "          -1.1484e-01,  4.5664e-01,  9.0020e-01, -5.0772e-01, -1.2571e+00,\n",
              "           1.9566e-01, -5.8033e-01,  3.1949e-01, -3.8078e-01,  2.5643e-01,\n",
              "          -1.9639e+00,  1.4191e-01,  1.9231e+00, -1.2477e-01,  1.5056e-01,\n",
              "           5.3557e-01,  1.4219e-01, -1.6073e+00,  1.0504e-01, -6.5094e-01,\n",
              "          -1.9060e+00,  6.0874e-01, -8.9919e-01, -1.1251e+00, -2.8457e-01,\n",
              "           6.4730e-01,  5.4524e-01, -7.9111e-01, -5.8191e-01,  1.1937e+00,\n",
              "           2.6465e-01,  3.2752e-02,  1.9172e+00,  8.3642e-01,  6.2696e-01,\n",
              "          -4.1755e-01,  1.4203e+00, -4.5128e-01,  4.8760e-01,  3.5352e-01,\n",
              "          -7.7435e-01, -9.1621e-02,  2.9711e-01, -1.1911e+00,  3.8133e-01],\n",
              "         [-9.7331e-03,  8.7352e-01, -1.1632e-01, -9.4248e-01,  3.1992e-01,\n",
              "          -1.0336e+00, -4.1290e-01,  2.1072e-01, -1.1937e+00,  1.4563e+00,\n",
              "          -1.2887e+00, -5.6145e-01,  4.1993e-01, -1.1768e-01, -2.0793e+00,\n",
              "           1.7534e-01,  1.5911e+00,  1.3913e+00,  6.4190e-01, -6.3414e-02,\n",
              "           1.0307e+00,  6.3824e-01,  1.4047e+00,  9.6078e-01,  1.8795e+00,\n",
              "          -2.2086e-01,  1.0386e+00,  7.7110e-01,  4.0979e-01, -1.9982e-01,\n",
              "          -4.0277e-01,  1.5097e+00, -1.3077e+00, -7.6394e-01, -8.9147e-01,\n",
              "           6.9542e-01, -1.7090e+00,  3.3051e-01,  6.0711e-01, -1.9119e-01,\n",
              "          -5.9976e-01, -1.6013e-01, -1.1885e+00, -5.4411e-01,  4.7581e-01,\n",
              "          -1.7934e-01, -2.0896e-01,  5.4581e-01,  8.1899e-01, -6.9609e-01],\n",
              "         [-1.2438e-01, -2.2023e-01, -1.0687e+00,  1.2418e-01,  1.2051e-01,\n",
              "          -1.6960e+00, -7.4463e-01, -2.1168e-01, -3.7330e-01,  2.9599e-01,\n",
              "          -3.4266e-01, -4.2867e-01,  5.8285e-01, -1.3563e+00,  1.0636e+00,\n",
              "           7.1789e-01,  2.3370e+00,  1.4118e+00,  7.0352e-01,  1.3604e+00,\n",
              "          -6.4603e-01, -6.7727e-01,  1.1194e+00,  1.1723e+00, -7.2833e-01,\n",
              "          -2.8910e-01, -8.8362e-01,  7.1007e-01, -9.6486e-01,  1.2508e+00,\n",
              "          -1.1917e+00, -9.0669e-01,  5.9606e-01,  7.5881e-01,  1.2276e+00,\n",
              "          -5.3930e-01,  1.6359e-01,  7.4290e-01,  2.0700e-01, -6.9205e-01,\n",
              "           1.5516e+00,  9.7819e-01, -3.0936e-01,  1.9000e-01,  4.8595e-01,\n",
              "          -1.2837e+00,  3.2090e-01, -1.1087e+00, -1.3288e-01,  2.3301e+00],\n",
              "         [ 9.7093e-02,  4.9633e-02,  9.4981e-01, -1.8219e+00, -2.1853e-01,\n",
              "          -4.3011e-01, -2.8379e-01,  1.0042e-01,  3.5927e-01, -1.5137e-01,\n",
              "           5.3839e-01,  2.3805e-01, -8.9259e-01,  8.1669e-01,  5.2966e-01,\n",
              "           3.5247e-01,  2.3862e+00, -3.8636e-01, -4.0453e-01, -1.1333e+00,\n",
              "          -1.8150e+00, -2.2543e-02,  5.9795e-04,  4.2813e-01, -2.9767e-01,\n",
              "           1.2388e+00, -1.0450e-01,  1.7498e-01,  5.3591e-01, -5.9035e-01,\n",
              "          -4.4663e-02,  2.5947e+00,  3.6850e-01,  1.2419e+00,  3.6213e-01,\n",
              "           6.5335e-01,  5.6521e-01, -3.9798e-01, -2.1234e-01,  1.3213e+00,\n",
              "           8.8398e-03, -1.6601e+00, -2.0459e-01, -1.3387e-01, -1.0545e+00,\n",
              "           1.1186e+00,  1.2362e-02, -1.4091e+00, -3.0491e+00, -7.5741e-01],\n",
              "         [-9.3419e-01, -1.7011e-01,  1.2649e+00, -2.8010e+00,  7.9848e-02,\n",
              "          -3.4062e-01, -4.6174e-01,  4.9144e-01, -1.6437e+00, -9.9108e-01,\n",
              "           5.5543e-01, -2.6159e-01,  1.0054e+00, -4.8324e-02,  4.4622e-01,\n",
              "           4.6834e-01,  4.9588e-01, -1.8387e-01, -6.6859e-01, -3.8845e-01,\n",
              "           3.1134e-01, -7.2108e-01, -3.3308e-03,  1.2354e-01,  3.2393e-02,\n",
              "           4.3517e-01,  5.3691e-01,  2.7673e-01, -1.2640e+00,  6.5888e-01,\n",
              "          -6.6498e-03, -6.1610e-01, -7.8272e-01, -1.7472e-01, -3.9839e-01,\n",
              "           3.3114e-01, -7.8909e-01,  2.6767e+00, -7.0835e-01, -1.0136e+00,\n",
              "           1.2568e+00,  1.0956e-01, -1.7491e+00, -4.5426e-01, -9.4777e-02,\n",
              "           1.5503e-01,  1.1983e+00, -1.2846e+00,  8.5334e-01, -9.6853e-01]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "sk9pltE_KVgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))"
      ],
      "metadata": {
        "id": "o-GmwXoHLpEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "-pd_QgE8Lu90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, answer in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(question)\n",
        "    # print(output.shape)\n",
        "\n",
        "    # loss -> output shape (1,324) - (1)\n",
        "    loss = criterion(output, answer[0])\n",
        "\n",
        "    # gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKITUSEnL-ol",
        "outputId": "880c15e4-ad88-496a-c8d6-d43c48fe01e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 522.839575\n",
            "Epoch: 2, Loss: 459.539747\n",
            "Epoch: 3, Loss: 383.053963\n",
            "Epoch: 4, Loss: 315.046708\n",
            "Epoch: 5, Loss: 260.704545\n",
            "Epoch: 6, Loss: 211.276192\n",
            "Epoch: 7, Loss: 166.976117\n",
            "Epoch: 8, Loss: 128.469853\n",
            "Epoch: 9, Loss: 97.677594\n",
            "Epoch: 10, Loss: 74.540930\n",
            "Epoch: 11, Loss: 57.334798\n",
            "Epoch: 12, Loss: 44.420794\n",
            "Epoch: 13, Loss: 35.437986\n",
            "Epoch: 14, Loss: 28.225866\n",
            "Epoch: 15, Loss: 23.409019\n",
            "Epoch: 16, Loss: 19.423714\n",
            "Epoch: 17, Loss: 16.354384\n",
            "Epoch: 18, Loss: 13.874365\n",
            "Epoch: 19, Loss: 11.956675\n",
            "Epoch: 20, Loss: 10.406005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "\n",
        "  # convert question to numbers\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "\n",
        "  # tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # find index of max prob\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index])"
      ],
      "metadata": {
        "id": "fbZzQT07WIqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the largest planet in our solar system?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ2DS-nubk5n",
        "outputId": "4f686430-2185-4877-ea09-2396654120ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jupiter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pHg7XdBzbnkA",
        "outputId": "c0b5eb78-be6e-4c9c-ad73-3e951fd660d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMzLzwL5c0Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When **each sequence in the batch has a different length**, you **cannot feed them directly into an RNN**.\n",
        "\n",
        "Why? Because tensors in a batch must all have the *same shape*, and RNN needs shape:\n",
        "\n",
        "```\n",
        "[batch_size, max_sequence_length, input_size]\n",
        "```\n",
        "\n",
        "But if lengths differ, example:\n",
        "\n",
        "```\n",
        "seq1: [12,  8,  3,  9]           length = 4\n",
        "seq2: [ 4,  7, 11]               length = 3\n",
        "seq3: [ 5,  6,  1,  9, 10]       length = 5\n",
        "```\n",
        "\n",
        "These cannot form a single rectangular tensor unless we make them the **same length.**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”´ Problem When Batch Lengths Differ\n",
        "\n",
        "You **cannot stack them:**\n",
        "\n",
        "```\n",
        "torch.tensor([\n",
        "  [12, 8, 3, 9],\n",
        "  [4, 7, 11],        âŒ cannot broadcast\n",
        "  [5, 6, 1, 9, 10]\n",
        "])\n",
        "```\n",
        "\n",
        "So RNN training fails.\n",
        "\n",
        "---\n",
        "\n",
        "# âœ”ï¸ Solutions\n",
        "\n",
        "There are **two main correct methods**:\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ **Method 1: Padding + pack_padded_sequence**\n",
        "\n",
        "### Step 1: Pad sequences to the same length\n",
        "\n",
        "For example, pad with a special `<PAD>` value (usually 0):\n",
        "\n",
        "```\n",
        "seq1 â†’ [12,  8,  3,  9,  0]\n",
        "seq2 â†’ [ 4,  7, 11,  0,  0]\n",
        "seq3 â†’ [ 5,  6,  1,  9, 10]\n",
        "```\n",
        "\n",
        "```python\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "padded = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "# padded shape â†’ [batch, max_len]\n",
        "```\n",
        "\n",
        "### Step 2: Use **pack_padded_sequence** so RNN ignores padded values\n",
        "\n",
        "```python\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "embedded = x(padded)  # [batch, max_len, emb]\n",
        "\n",
        "pack = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
        "output, hidden = y(pack)  # RNN now ignores padded zeros\n",
        "```\n",
        "\n",
        "ðŸ“Œ **Advantage:** faster, ignores padding **correctly**\n",
        "ðŸ“Œ **Required when training NLP models**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ **Method 2: Padding Only (no packing)**\n",
        "\n",
        "You can pad and directly send into RNN:\n",
        "\n",
        "```python\n",
        "padded = pad_sequence(batch, batch_first=True)\n",
        "output, hidden = y(x(padded))\n",
        "```\n",
        "\n",
        "âš ï¸ But RNN **will compute on padding tokens**, which **hurts training accuracy**, **wastes compute**, etc.\n",
        "\n",
        "ðŸ‘‰ Use only if model is simple or inference-only.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  Summary Table\n",
        "\n",
        "| Method                 | Padding Needed? | RNN ignores padding? | Best use case          |\n",
        "| ---------------------- | --------------- | -------------------- | ---------------------- |\n",
        "| `pack_padded_sequence` | âœ” Yes           | âœ” Yes                | NLP training           |\n",
        "| Pad only               | âœ” Yes           | âŒ No                 | quick tests, inference |\n",
        "| No padding             | âŒ               | âŒ                    | âŒ impossible           |\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§© Visualization\n",
        "\n",
        "```\n",
        "Before pad:      Different lengths âŒ\n",
        "Batch:\n",
        "  [12, 8, 3, 9]\n",
        "  [4, 7, 11]\n",
        "  [5, 6, 1, 9, 10]\n",
        "\n",
        "After pad:       Same length âœ”\n",
        "Batch:\n",
        "  [12, 8, 3, 9,  0]\n",
        "  [4, 7,11, 0,  0]\n",
        "  [5, 6, 1, 9, 10]\n",
        "```\n",
        "\n",
        "Then pack ignoring padding.\n",
        "\n"
      ],
      "metadata": {
        "id": "vTgUHnH-xvdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GdqGu6Mjxv0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}